{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.])\n"
     ]
    }
   ],
   "source": [
    "V_data = [1.,2.,3.]\n",
    "V = torch.Tensor(V_data)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.]])\n"
     ]
    }
   ],
   "source": [
    "M = [[1.,2.,3.],[4.,5.,6.]]\n",
    "M = torch.Tensor(M)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]]])\n"
     ]
    }
   ],
   "source": [
    "T_data = [[[1.,2.],[3.,4.]],[[5.,6.],[7.,8.]]]\n",
    "T = torch.Tensor(T_data)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "print(T[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5431, -1.2956, -0.4681,  0.8674, -1.0671],\n",
       "         [-0.2257,  1.9390,  0.5736,  0.7181, -0.8138],\n",
       "         [ 0.7730, -0.1040,  1.5151,  1.4084,  0.5299],\n",
       "         [-1.3353,  1.4416,  0.4625,  0.7972, -0.1488]],\n",
       "\n",
       "        [[ 0.3746, -0.6750,  0.0336,  0.7138,  2.2252],\n",
       "         [ 0.1328,  0.1231, -0.2180,  1.1797,  0.3777],\n",
       "         [ 0.2926,  0.7864, -0.0342, -1.3068,  0.5694],\n",
       "         [-0.0596, -0.3087, -0.0857,  0.8599,  1.6077]],\n",
       "\n",
       "        [[ 0.5246,  0.5291, -0.0770,  0.3224,  0.4370],\n",
       "         [-1.8931, -0.5044,  1.4705, -0.9269, -0.2306],\n",
       "         [-0.8672,  1.1268, -1.8941,  1.8757,  0.6530],\n",
       "         [-0.0440,  1.3589,  0.0806,  0.8197, -1.1764]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,4,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.cat([x,y])\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5431, -1.2956, -0.4681,  0.8674, -1.0671, -0.2257],\n",
      "        [ 1.9390,  0.5736,  0.7181, -0.8138,  0.7730, -0.1040],\n",
      "        [ 1.5151,  1.4084,  0.5299, -1.3353,  1.4416,  0.4625],\n",
      "        [ 0.7972, -0.1488,  0.3746, -0.6750,  0.0336,  0.7138],\n",
      "        [ 2.2252,  0.1328,  0.1231, -0.2180,  1.1797,  0.3777],\n",
      "        [ 0.2926,  0.7864, -0.0342, -1.3068,  0.5694, -0.0596],\n",
      "        [-0.3087, -0.0857,  0.8599,  1.6077,  0.5246,  0.5291],\n",
      "        [-0.0770,  0.3224,  0.4370, -1.8931, -0.5044,  1.4705],\n",
      "        [-0.9269, -0.2306, -0.8672,  1.1268, -1.8941,  1.8757],\n",
      "        [ 0.6530, -0.0440,  1.3589,  0.0806,  0.8197, -1.1764],\n",
      "        [ 1.0229, -0.6546, -0.7756,  0.1010, -2.9044,  0.7951],\n",
      "        [ 1.3056,  1.4233, -0.4405, -1.0838,  0.7521, -0.5250],\n",
      "        [-1.4369,  1.8602,  0.0416,  1.8228,  0.0137,  1.1245],\n",
      "        [ 0.7639, -0.6786, -0.2294,  1.1256,  1.3904,  0.4277],\n",
      "        [ 2.3831,  0.5883,  0.0182, -0.3897,  0.4537,  0.6084],\n",
      "        [-1.1868,  0.8026, -0.0947,  0.0273,  0.4601,  2.8623],\n",
      "        [ 1.2144,  2.3664,  1.5989, -0.2486,  0.2581, -0.3959],\n",
      "        [-1.4739, -0.5554, -0.7013, -0.1926,  0.6554, -0.1567],\n",
      "        [-0.2772, -1.5749,  0.3705, -0.5404,  0.1317, -1.9238],\n",
      "        [-0.6479, -0.9599,  0.5486,  0.8995,  1.2128, -0.6098]])\n"
     ]
    }
   ],
   "source": [
    "print(z.view(20,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((1,3),requires_grad = True)\n",
    "#print(x)\n",
    "y = torch.randn((1,3), requires_grad = True)\n",
    "z = x * y\n",
    "s = z.sum()\n",
    "s.grad_fn\n",
    "s.backward()\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "None\n",
      "<AddBackward1 object at 0x7f6c6fa5dc88>\n",
      "True\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2)\n",
    "y = torch.randn(2, 2)\n",
    "# By default, user created Tensors have ``requires_grad=False``\n",
    "print(x.requires_grad, y.requires_grad)\n",
    "z = x + y\n",
    "# So you can't backprop through z\n",
    "print(z.grad_fn)\n",
    "\n",
    "# ``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
    "# flag in-place. The input flag defaults to ``True`` if not given.\n",
    "x = x.requires_grad_()\n",
    "y = y.requires_grad_()\n",
    "# z contains enough information to compute gradients, as we saw above\n",
    "z = x + y\n",
    "print(z.grad_fn)\n",
    "# If any input to an operation has ``requires_grad=True``, so will the output\n",
    "print(z.requires_grad)\n",
    "\n",
    "# Now z has the computation history that relates itself to x and y\n",
    "# Can we just take its values, and **detach** it from its history?\n",
    "new_z = z.detach()\n",
    "\n",
    "# ... does new_z have information to backprop to x and y?\n",
    "# NO!\n",
    "print(new_z.grad_fn)\n",
    "# And how could it? ``z.detach()`` returns a tensor that shares the same storage\n",
    "# as ``z``, but with the computation history forgotten. It doesn't know anything\n",
    "# about how it was computed.\n",
    "# In essence, we have broken the Tensor away from its past history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Affine maps **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3488,  0.3756,  0.3832],\n",
       "        [ 0.7868,  0.9429, -0.2002]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = nn.Linear(5,3)\n",
    "data = torch.randn(2,5)\n",
    "lin(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7928,  1.1799,  0.5760],\n",
       "        [-0.1716,  0.8839, -0.2836]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.randn(2,3)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7928,  1.1799,  0.5760],\n",
       "        [ 0.0000,  0.8839,  0.0000]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.relu(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0894,  0.4378, -0.1655, -0.3901,  0.2640]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.randn(1,5)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6487,  0.1244,  0.0680,  0.0543,  0.1045]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(data, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4328, -2.0844, -2.6877, -2.9124, -2.2583]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(data, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
